# -*- coding: utf-8 -*-
"""practica07.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g7PKMNmw6w-2_71hicIu4PhEOvgUcRY8

# Practica 07

Alumno: David Pérez Jacome \\
Número de Cuenta: 316330420

**Actividades**

1. Explorar los datasets disponibles en el Shared Task de Open Machine Translation de AmericasNLP 2021
  - Datasets
  - Readme

2. Crear un modelo de traducción neuronal usando OpenNMT-py y siguiendo el pipeline visto en clase
  - 0.Obtención de datos y preprocesamiento
    - Considerar que tiene que entrenar su modelo de tokenization
  - a.Configuración y entrenamiento del modelo
  - b.Traducción
  - c.Evaluación
    - Reportar BLEU
    - Reportar ChrF (medida propuesta para el shared task)
3. Comparar resultados con baseline
4. Incluir el archivo *.translated.desubword

**Extra**

1. Investigar porque se propuso la medida ChrF en el Shared Task
  - ¿Como se diferencia de BLEU?
  - ¿Porqué es reelevante utilizar otras medidas de evaluación además de BLEU?

El propósito de la medida ChrF (Character F-score) en el contexto del Shared Task podría estar relacionado con las limitaciones percibidas del BLEU (Bilingual Evaluation Understudy) y la necesidad de medidas de evaluación más robustas y adecuadas para ciertos tipos de traducción.

1. Enfoque en caracteres: ChrF se basa en la coincidencia de caracteres, lo que lo hace adecuado para lenguajes que pueden tener una gran variabilidad léxica o una riqueza morfológica, como los idiomas aglutinantes o los lenguajes con alfabetos no latinos.

2. Sensibilidad a la fluidez: A diferencia de BLEU, que se centra en la coincidencia de n-gramas, ChrF también tiene en cuenta la fluidez de la traducción al considerar la cantidad de palabras y caracteres comunes entre las traducciones de referencia y la hipótesis de traducción.

3. Adaptabilidad a diferentes tareas y dominios: ChrF puede ser más flexible que BLEU para adaptarse a diferentes dominios o tareas de traducción, ya que su enfoque en caracteres puede capturar mejor las similitudes entre las traducciones de referencia y la salida del modelo en diversas condiciones.

**Diferencias entre ChrF y BLEU:**

1. Caracteres vs. n-gramas: ChrF se centra en la coincidencia de caracteres, mientras que BLEU se basa en la coincidencia de n-gramas (secuencias de palabras). Esto hace que ChrF sea más robusto para lenguajes con estructuras morfológicas complejas o para tareas donde la precisión de caracteres es crítica.
2. Sensibilidad a la fluidez: ChrF tiene en cuenta tanto la precisión como la fluidez, mientras que BLEU se centra principalmente en la precisión. Esto significa que ChrF puede penalizar las traducciones que son gramaticalmente incorrectas o que tienen una estructura incoherente.

**Importancia de utilizar otras medidas de evaluación además de BLEU**

1. Limitaciones de BLEU: BLEU es una métrica popular pero tiene sus limitaciones, como la insensibilidad a la reordenación de palabras, la falta de sensibilidad a la fluidez y la incapacidad para capturar la semántica de las traducciones. Por lo tanto, utilizar solo BLEU puede no proporcionar una evaluación completa y precisa del rendimiento del modelo de traducción.
2. Variedad de tareas y lenguajes: Diferentes tareas de traducción y lenguajes pueden requerir métricas de evaluación diferentes. Al utilizar otras medidas como ChrF, se puede obtener una evaluación más completa que tenga en cuenta la diversidad lingüística y las características específicas de la tarea.
"""

import os
import subprocess
import requests

# Función para descargar archivos
def download_file(url, file_name):
    with open(file_name, "wb") as f:
        response = requests.get(url)
        f.write(response.content)

# Paso 1: Descargar los conjuntos de datos
urls = [
    "https://github.com/AmericasNLP/americasnlp2021/raw/main/data/train.es",
    "https://github.com/AmericasNLP/americasnlp2021/raw/main/data/train.en",
    "https://github.com/AmericasNLP/americasnlp2021/raw/main/data/dev.es",
    "https://github.com/AmericasNLP/americasnlp2021/raw/main/data/dev.en"
]

for url in urls:
    file_name = url.split("/")[-1]
    download_file(url, file_name)

# Paso 2: Instalar OpenNMT-py
!pip install OpenNMT-py

# Paso 3: Preprocesamiento de datos
subprocess.run("onmt_preprocess -train_src train.es -train_tgt train.en -valid_src dev.es -valid_tgt dev.en -save_data data -overwrite", shell=True)

# Paso 4: Configuración y entrenamiento del modelo
model_config = """
model_dir: modelo
data:
    train: data.train
    valid: data.dev
save_model: modelo/model
train_steps: 10000
save_checkpoint_steps: 500
world_size: 1
gpu_ranks: [0]
"""
with open("modelo.yaml", "w") as f:
    f.write(model_config)

# Entrenar el modelo
subprocess.run("onmt_train -config modelo.yaml", shell=True)

# Paso 5: Traducción
subprocess.run("onmt_translate -model modelo/model_step_10000.pt -src dev.es -output pred.txt -gpu 0", shell=True)

# Paso 6: Evaluación
subprocess.run("onmt_score -ref dev.en -hyp pred.txt", shell=True)

# Paso 7: Comparación con el baseline

# Paso 8: Inclusión del archivo *.translated.desubword
subprocess.run("sed 's/@@ //g' pred.txt > pred.desubword", shell=True)